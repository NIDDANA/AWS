{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6316d0a7",
   "metadata": {},
   "source": [
    "### Steps to be followed\n",
    "1. importing necessary libraries\n",
    "2. Create S3 Bucket\n",
    "3. mapping train and test data in S3\n",
    "4. Mapping the path of the model in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36bdfc",
   "metadata": {},
   "source": [
    "### The use of S3 Bucket is, \n",
    "1. In this we will be able to save the training and test data of our model.\n",
    "2. What ever model we have trained in the sage maker we will save in the S3 Bucket\n",
    "3. It acts as a stroage unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8590c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3 # when ever we work with the sagemaker we have to import BOTO3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c62bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71732f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = \"bankapplications\"  # Example bucket name, adjust as needed\n",
    "my_region = boto3.session.Session().region_name\n",
    "print(\"Selected region:\", my_region)\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "try:\n",
    "    if my_region == \"us-east-1\":\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': my_region})\n",
    "        print(\"S3 bucket '{}' successfully created.\".format(bucket_name))\n",
    "except Exception as e:\n",
    "    print(\"S3 error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b604a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bankapplications/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "#set an output path where the trained model will be saved\n",
    "prefix = \"xgboost-as-a-built-in-algo\"\n",
    "output_path = \"s3://{}/{}/output\".format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d953a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess: Downloaded bank_clean.csv\n",
      "Sucess: data loaded into the dataframe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print(\"Sucess: Downloaded bank_clean.csv\")\n",
    "except Exception as e:\n",
    "    print(\"data load eerror: \", e)\n",
    "\n",
    "try:\n",
    "    model_name = pd.read_csv(\"./bank_clean.csv\", index_col = 0)\n",
    "    print(\"Sucess: data loaded into the dataframe\")\n",
    "except Exception as e:\n",
    "    print(\"data load error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed731548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "# train test split using numpy library\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data, test_data = np.split(model_name.sample(frac=1, random_state=124), [int(0.7*len(model_name))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5cccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b516f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Test Into Buckets\n",
    "## We start with Test Data\n",
    "import os\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8639f",
   "metadata": {},
   "source": [
    "## Building the xgboost inbuilt algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f591dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "\n",
    "import sagemaker\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    \"xgboost\", region=boto3.Session().region_name, version = \"1.2-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a0d0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02af4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, \n",
    "                                          output_path=output_path,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "090198fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da92e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-08-20-17-19-56-480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-20 17:19:56 Starting - Starting the training job...\n",
      "2023-08-20 17:20:12 Starting - Preparing the instances for training......\n",
      "2023-08-20 17:21:09 Downloading - Downloading input data...\n",
      "2023-08-20 17:21:50 Training - Training image download completed. Training in progress....\n",
      "2023-08-20 17:22:21 Uploading - Uploading generated training model\u001b[34m[2023-08-20 17:22:13.263 ip-10-0-213-242.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.426 ip-10-0-213-242.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.427 ip-10-0-213-242.ec2.internal:7 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.427 ip-10-0-213-242.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.428 ip-10-0-213-242.ec2.internal:7 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.428 ip-10-0-213-242.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 28831 rows and 59 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.10149#011validation-error:0.10294\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.478 ip-10-0-213-242.ec2.internal:7 INFO hook.py:413] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2023-08-20 17:22:13.482 ip-10-0-213-242.ec2.internal:7 INFO hook.py:476] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.10083#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.10045#011validation-error:0.10229\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.10066#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.10034#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.10038#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.10017#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.10055#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.10038#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.10007#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.10007#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.09993#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.10003#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09996#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.09979#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.09986#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.09958#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.09955#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09965#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09958#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09968#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09951#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09979#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09958#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09913#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09899#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09871#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09871#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09844#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09833#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09847#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09816#011validation-error:0.10245\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09830#011validation-error:0.10237\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09850#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09864#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09847#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09819#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09830#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09830#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09802#011validation-error:0.10197\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09816#011validation-error:0.10213\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09837#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09823#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09819#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09809#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09816#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09799#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09802#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09805#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09781#011validation-error:0.10156\u001b[0m\n",
      "\n",
      "2023-08-20 17:22:31 Completed - Training job completed\n",
      "Training seconds: 82\n",
      "Billable seconds: 41\n",
      "Managed Spot Training savings: 50.0%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\": s3_input_train, \"validation\": s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac00534",
   "metadata": {},
   "source": [
    "## Deploy Machine Learning Model As Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a6aeeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-08-20-17-26-24-566\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2023-08-20-17-26-24-566\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2023-08-20-17-26-24-566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59932e6e",
   "metadata": {},
   "source": [
    "### prediction of the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8495308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Assuming you already have the xgb_predictor object created\n",
    "\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = CSVSerializer()  # Use the CSVSerializer from sagemaker.serializers\n",
    "\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8')\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',')\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5100ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03087804, 0.04877723, 0.07058939, ..., 0.05399493, 0.33494297,\n",
       "       0.03112546])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19bd2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.8%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10787)    34% (163)\n",
      "Purchase        9% (1092)     66% (315) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bb1a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-xgboost-2023-08-20-17-26-24-566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'F5N0WRSKD53FF0J3',\n",
       "   'HostId': 'MoVrFokLLNAzlvTQmMV9BlxeGL/fGt0UID73sK2vz1CU4sHmx0YvHnLx1xXgb2dzn8501XM+tbKp7CazeSQVjQ==',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'MoVrFokLLNAzlvTQmMV9BlxeGL/fGt0UID73sK2vz1CU4sHmx0YvHnLx1xXgb2dzn8501XM+tbKp7CazeSQVjQ==',\n",
       "    'x-amz-request-id': 'F5N0WRSKD53FF0J3',\n",
       "    'date': 'Sun, 20 Aug 2023 17:38:30 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/profiler-output/system/incremental/2023082017/1692552120.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/profiler-output/system/incremental/2023082017/1692552060.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-08-20-17-19-56-480/output/model.tar.gz'}]}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleteling the end points\n",
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a78c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
